[
  {
    "id": "rtx-5090",
    "name": "GeForce RTX 5090 PNY",
    "manufacturer": "NVIDIA",
    "architecture": "Blackwell",
    "specs": {
      "cudaCores": 21760,
      "tensorCores": 680,
      "rayTracingCores": 170,
      "baseClockSpeed": "2.01 GHz",
      "boostClockSpeed": "2.41 GHz",
      "memoryType": "GDDR7",
      "memorySize": "32 GB",
      "memoryBusWidth": "512-bit",
      "memoryBandwidth": "1,792 GB/s",
      "transistorCount": "92 billion",
      "dieSize": "750 mm²",
      "tdp": "575 W"
    },
    "launchDate": "2025-01-30",
    "launchMsrp": "$1,999",
    "keyFeatures": [
      "GDDR7 memory",
      "PCIe 5.0 interface",
      "DisplayPort 2.1b connectors supporting up to 8K at 165Hz",
      "DLSS 4 technology with Multi Frame Generation and AI enhancements"
    ],
    "performance": "Offers twice the performance of the RTX 4090",
    "description": "NVIDIA's flagship consumer GPU, targeting gamers and content creators, featuring advanced ray tracing and AI capabilities.",
    "category": "consumer",
    "tags": ["gaming", "content-creation", "ray-tracing", "AI"],
    "image": "/images/GPU_RTX-5090-PNY.png",
    "featured": true
  },
  {
    "id": "h-100",
    "name": "H100 SGX",
    "manufacturer": "NVIDIA",
    "architecture": "Hopper",
    "specs": {
      "cudaCores": 14592,
      "tensorCores": 456,
      "rayTracingCores": "N/A",
      "baseClockSpeed": "1.095 GHz",
      "boostClockSpeed": "1.755 GHz",
      "memoryType": "HBM2e",
      "memorySize": "80 GB",
      "memoryBusWidth": "5120-bit",
      "memoryBandwidth": "2,040 GB/s",
      "transistorCount": "80 billion",
      "dieSize": "814 mm²",
      "tdp": "350 W"
    },
    "launchDate": "2023-03-21",
    "launchMsrp": "$30,000",
    "keyFeatures": [
      "HBM2e memory",
      "PCIe 5.0 interface",
      "NVLink support",
      "4th generation Tensor Cores",
      "Transformer Engine with FP8 precision"
    ],
    "performance": "Delivers up to 3X higher performance for AI training and up to 30X higher performance for AI inference compared to the previous generation.",
    "description": "NVIDIA's data center GPU designed for high-performance computing and AI workloads, featuring exceptional performance for large language models and deep learning applications.",
    "category": "datacenter",
    "tags": ["HPC", "AI", "data-center", "enterprise", "LLM"],
    "image": "/images/GPU_H100-SGX.png",
    "featured": true
  },
  {
    "id": "h-200",
    "name": "H200 SGX",
    "manufacturer": "NVIDIA",
    "architecture": "Hopper",
    "specs": {
      "cudaCores": 17000,
      "tensorCores": 680,
      "rayTracingCores": "N/A",
      "baseClockSpeed": "1.8 GHz",
      "boostClockSpeed": "2.3 GHz",
      "memoryType": "HBM3",
      "memorySize": "80 GB",
      "memoryBusWidth": "5120-bit",
      "memoryBandwidth": "3,276 GB/s",
      "transistorCount": "80 billion",
      "dieSize": "814 mm²",
      "tdp": "700 W"
    },
    "launchDate": "2024-11-01",
    "launchMsrp": "$10,000",
    "keyFeatures": [
      "HBM3 memory",
      "PCIe 5.0 interface",
      "NVLink support",
      "Enhanced AI and HPC capabilities"
    ],
    "performance": "Designed for high-performance computing and AI workloads, delivering significant performance improvements over its predecessor, the H-100.",
    "description": "Part of NVIDIA's data center lineup, optimized for high-performance computing (HPC) and artificial intelligence (AI) workloads, offering substantial memory and computational power.",
    "category": "datacenter",
    "tags": ["HPC", "AI", "data-center", "enterprise"],
    "image": "/images/GPU_H200-SGX.png",
    "featured": true
  }
] 